{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations and challenges in mobility data: noise for multiple devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import uuid\n",
    "from copy import deepcopy\n",
    "\n",
    "import geopandas as gpd\n",
    "import h3\n",
    "import pandas as pd\n",
    "from dwells_geometries import gdf_geometries\n",
    "from IPython.display import Image\n",
    "from kepler_configs import config_agg_noiseless, config_agg_noisy\n",
    "from keplergl import KeplerGl\n",
    "from noisyfier import Noisyfier, Sink\n",
    "from shapely.geometry import Polygon\n",
    "from simulate_data import create_ideal_L_shape_trajectory__sydney\n",
    "\n",
    "# Set to True to render the kepler map or altair charts when running the notebook in local\n",
    "# If False, screenshots will be shown instead\n",
    "INTERACTIVE_OUTPUT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create noiseless trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = random.Random()\n",
    "rd.seed(42)\n",
    "\n",
    "entity_ids = [uuid.UUID(int=rd.getrandbits(128), version=4).hex[:8] for _ in range(7)]\n",
    "\n",
    "list_noiseless_trajectories = []\n",
    "for idx in entity_ids:\n",
    "    list_noiseless_trajectories += [create_ideal_L_shape_trajectory__sydney(entity_id=idx)]\n",
    "\n",
    "df_noiseless_trajectories = pd.concat(list_noiseless_trajectories).sort_values(\"timestamp\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate noiseless trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noiseless_trajectories_agg = df_noiseless_trajectories.copy()\n",
    "df_noiseless_trajectories_agg[\"H3_min\"] = df_noiseless_trajectories_agg.apply(\n",
    "    lambda row: f\"{h3.geo_to_h3(row['latitude'], row['longitude'], resolution=12)}_{row['timestamp'].round('5min')}\",\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df_noiseless_trajectories_agg[\"H3\"] = df_noiseless_trajectories_agg[\"H3_min\"].apply(lambda row: row.split(\"_\")[0])\n",
    "df_noiseless_trajectories_agg[\"min\"] = df_noiseless_trajectories_agg[\"H3_min\"].apply(lambda row: row.split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h3_heatmap_before_noise = (\n",
    "    pd.DataFrame(df_noiseless_trajectories_agg.groupby(\"H3\").size())\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"num_pings_per_hex\"})\n",
    ")\n",
    "\n",
    "polygonise = lambda hex_id: Polygon(\n",
    "    h3.h3_to_geo_boundary(hex_id, geo_json=True)\n",
    ")  # noqa:  E731 do not assign a lambda expression, use a def\n",
    "gdf_heatmap_before_noise = gpd.GeoDataFrame(\n",
    "    df_h3_heatmap_before_noise.copy(),\n",
    "    geometry=list(map(polygonise, df_h3_heatmap_before_noise[\"H3\"])),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "\n",
    "gdf_heatmap_before_noise = gdf_heatmap_before_noise.drop(columns=[\"H3\"]).reset_index(drop=True)\n",
    "kepler_data = {\n",
    "    \"Dwell locations\": gdf_geometries,\n",
    "    \"Signal before noise\": gdf_heatmap_before_noise,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INTERACTIVE_OUTPUT:\n",
    "    map_1 = KeplerGl(data=deepcopy(kepler_data), height=1100, config=config_agg_noiseless)\n",
    "    display(map_1)\n",
    "else:\n",
    "    display(Image(\"images/noise_agg_0_perfect_aggregates.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add noise to trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisifyier = Noisyfier(df_noiseless_trajectories)\n",
    "\n",
    "noisifyier.spatial_stationary_spread(\n",
    "    spread=7,\n",
    "    keywords=(\n",
    "        \"moving\",\n",
    "        \"entering\",\n",
    "    ),\n",
    "    noise_model=\"gaussian\",\n",
    ")\n",
    "\n",
    "\n",
    "noisifyier.temporal_varying_spread(\n",
    "    lower_bound_sec=0,\n",
    "    upper_bound_sec=60,\n",
    "    lower_bound_spread_sec=1,\n",
    "    upper_bound_spread_sec=20,\n",
    "    noise_model=\"gumbel\",  # can be \"uniform\", \"gaussian\", \"gumbel\"\n",
    "    variational_model=\"periodic\",  # can be \"linear\" or \"periodic\"\n",
    ")\n",
    "\n",
    "noisifyier.spatial_varying_spread(\n",
    "    lower_bound_sec=0,\n",
    "    upper_bound_sec=5 * 60,\n",
    "    lower_bound_spread_m=1,\n",
    "    upper_bound_spread_m=30,\n",
    "    keywords=(\"dwell\",),\n",
    "    noise_model=\"gaussian\",\n",
    "    variational_model=\"periodic\",\n",
    ")\n",
    "\n",
    "noisifyier.spatial_varying_spread(\n",
    "    lower_bound_sec=0,\n",
    "    upper_bound_sec=180,\n",
    "    lower_bound_spread_m=1,\n",
    "    upper_bound_spread_m=8,\n",
    "    keywords=(\n",
    "        \"moving\",\n",
    "        \"entering\",\n",
    "    ),\n",
    "    noise_model=\"uniform\",\n",
    "    variational_model=\"periodic\",\n",
    ")\n",
    "\n",
    "noisifyier.missing_points(\n",
    "    frequency=0.6,\n",
    "    reliability_model=\"uniform\",\n",
    "    keywords=(),\n",
    ")\n",
    "\n",
    "noisifyier.missing_points(\n",
    "    frequency=0.4,\n",
    "    reliability_model=\"bathtub\",\n",
    "    keywords=(\"moving\",),\n",
    ")\n",
    "\n",
    "noisifyier.missing_points(frequency=0.95, reliability_model=\"triangular_increasing\", keywords=(\"dwell\",))\n",
    "\n",
    "noisifyier.gridding(\n",
    "    precision=3,\n",
    "    frequency=0.05,\n",
    "    reliability_model=\"uniform\",\n",
    ")\n",
    "\n",
    "noisifyier.erratic_points(\n",
    "    frequency=0.03,\n",
    "    reliability_model=\"uniform\",\n",
    "    keywords=(\"moving\",),\n",
    "    buffer_width_meters=50,\n",
    "    total_sampling_for_erratic_points=1000,\n",
    ")\n",
    "\n",
    "sink_rugby_club = Sink(151.176491, -33.889456, 0.03, \"triangular_increasing\")\n",
    "\n",
    "noisifyier.sink_locations(\n",
    "    list_sinks=[\n",
    "        sink_rugby_club,\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_noisy_trajectories = noisifyier.df_pings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Aggregate noisy trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noisy_trajectories_agg = df_noisy_trajectories.copy()\n",
    "df_noisy_trajectories_agg[\"H3_min\"] = df_noisy_trajectories_agg.apply(\n",
    "    lambda row: f\"{h3.geo_to_h3(row['latitude'], row['longitude'], resolution=12)}_{row['timestamp'].round('5min')}\",\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df_noisy_trajectories_agg[\"H3\"] = df_noisy_trajectories_agg[\"H3_min\"].apply(lambda row: row.split(\"_\")[0])\n",
    "df_noisy_trajectories_agg[\"min\"] = df_noisy_trajectories_agg[\"H3_min\"].apply(lambda row: row.split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noisy_trajectories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h3_heatmap_with_noise = (\n",
    "    pd.DataFrame(df_noisy_trajectories_agg.groupby(\"H3\").size()).reset_index().rename(columns={0: \"num_pings_per_hex\"})\n",
    ")\n",
    "\n",
    "gdf_heatmap_with_noise = gpd.GeoDataFrame(\n",
    "    df_h3_heatmap_with_noise.copy(),\n",
    "    geometry=list(map(polygonise, df_h3_heatmap_with_noise[\"H3\"])),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "\n",
    "gdf_heatmap_with_noise = gdf_heatmap_with_noise.drop(columns=[\"H3\"]).reset_index(drop=True)\n",
    "kepler_data = {\n",
    "    \"Dwell locations\": gdf_geometries,\n",
    "    \"Signal with noise\": gdf_heatmap_with_noise,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INTERACTIVE_OUTPUT:\n",
    "    map_1 = KeplerGl(data=deepcopy(kepler_data), height=1100, config=config_agg_noisy)\n",
    "    display(map_1)\n",
    "else:\n",
    "    display(Image(\"images/noise_agg_1_noisy_aggregates.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
